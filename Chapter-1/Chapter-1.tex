%SourceDoc ../YourName-Dissertation.tex
\chapter{Introduction} \label{chapter:introduction}
\section{Ash hazards forecast}
Explosive volcanism is one of the most catastrophic
phenomena on the earth.
Reducing risk and the losses caused by explosive volcanic hazards is one of the most important challenges.
Primary hazards associated with explosive volcanic eruptions include pyroclastic density currents (flows and surges), the widespread deposition of airfall tephra, and the threats to aviation posed by volcanic ash in the atmosphere. Simulation of all possible hazards with one model is difficult due to the fact that different length scales dominate different hazards. Focus of this work is the hazard related to volcanic ash in the atmosphere. For example. exposure of aircraft to ash can result in extensive damages to windshields, electrical and hydraulic systems, blocking of pitot tubes, and leads to engine malfunction and failure \citep{peterson2008forecasting}. Flgihts are usually cancelled or rescheduled to avoid flying through volcano ash, resulting in massive economic loss.

In recent years significant advances in
the identification of volcanic ash through satellite observations, which provide snapshots of ash cloud concentration downwind, facilitates forcasting of ash forecast essentially.
However, satellite data are limited to the highest visible layer. Meteorological clouds obscure ash clouds beneath them and multiple ash layers may develop. Both factors compromise satellite measurements. Furthermore, satellites can provide timely observations of where the volcanic ash is currently located, but hazard assessments
require forecasting. Consequently, numerical estimation of ash distribution using known wind fields must accompany satellite estimates of ash concentration to accurately predict ash cloud evolution.

VATDs (volcanic ash transport and dispersion models) are usually used to numerically forecast the location and movement of ash clouds at timescales that range from hours to days. VATDs use eruption source parameters, such as plume height, mass eruption rate, duration, and the mass fraction distribution of erupted particles finer than about $4 \Phi$ (or $62.5 \mu$m), which can remain in the cloud for many hours or days. Observational data for such parameters are usually unavailable in the first minutes or hours after an eruption is detected. Moreover, these input parameters are subject to change during an eruption, requiring rapid re-assignment of new parameters. Usually, plume models are used to provide these source terms for VATDs and the forecast accuracy is critically dependent on these models. This thesis reports on a new 3D (three dimensional) volcanic plume model based on smoothed particle hydrodynamic (SPH) method with the expectation of providing more accurate source terms to VATDs.

\section{Volcanic Plume Modeling}
\subsection{Existing 1D plume models}
The basic physics of volcanic plumes has been studied for more than half a century \citep{morton1956turbulent, settle1978volcanic, wilson1978control}. The effects of magma type and vent conditions \citep{woods1988fluid, woods1995decompression}, atmospheric conditions \citep{ woods1993moist, sparks1997volcanic, bursik2001effect}, external surface water \citep{koyaguchi1996formation}, thermal disequilibrium, and particle fallout \citep{woods1991particle} have been assessed in increasing details based on observation, experiments and numerical studies.

Several 1D (one dimensional) volcanic plume models have been developed in the past few decades, ranging from the most basic 1D model \citep{woods1988fluid} which only accounts for mass conservation to more recently developed 1D models  \citep{bursik2001effect, mastin2007user, degruyter2012improving, woodhouse2013interaction, devenish2013using, girault2014effect, de2015plume, vitturi2015plume, folch2016fplume, pouget2016sensitivity} which tend to account for more comprehensive physics effects. 
For example, FPLUME-1.0 \citep{folch2016fplume} accounts for wind effect, entrainment of moisture, water phase change, particle fallout and re-entrainment and even wet aggregation of ash. However, in these 1D models, the entrainment of air is evaluated based on two coefficients: entrainment coefficient due to turbulence in the rising buoyant jet and the crosswind field. Different 1D models adopt different entrainment coefficients based on specific formulation or calibration against well-documented case studies. The feedback from plume to atmosphere is usually ignored in 1D models. Even though determination of essential parameters such as the entrainment is not based on first principles, such simple models nevertheless allow us to investigate the importance of physical mechanisms in a volcanic plume. In addition, these simplified models require little computational resource and can run on standard personal computers or on web sites in very short time. As a result, 1D software for volcanic plume development \citep[such as][]{267, 1194, 3541}, combined with VATDs \citep[such as][]{114} are widely used in research and practice. While these 1D models can generate well-matched results with 3D models for weak plumes, much greater variability is observed for strong plume scenarios, especially for local variables \citep{costa2016results}. In addition, there is need for greater skill in hazards forecasts especially where the plume model is used to generate source conditions for complex 2D (two dimensional) and 3D VATD models.

\subsection{Existing 3D plume models}

The development of 2D and 3D, time-dependent, and multiphase numerical models for volcanic plumes has provided new explanations for many features of explosive volcanism. One of the earliest of these is the 3D model PDAC (Pyroclastic Dispersion Analysis Code) \citep{neri2003multiparticle}  which is a non-equilibrium, multiphase, 3D compressible flow model. Conservation equations for each phase are solved separately with the finite volume method. A parallel computing version of PDAC was also developed \citep{ongaro2007parallel}. Advanced numerical techniques, such as a second order scheme and semi-explicit time stepping, was also adopted afterwards to improve the accuracy of PDAC \citep{carcano2013semi}. 

Another 3D model, SK-3D \citep{suzuki2005numerical} is a 3D time-dependent fluid dynamics model that attempts to reproduce the entrainment process of eruption clouds with relatively simple physics but with high order numerical accuracy and high spatial resolution.
A series of simulations based on SK-3D was reported, including establishment of the relationship between the observable quantities of the eruption clouds and the eruption conditions at the vent \citep{suzuki2009three}, investigation of the effect of the intensity of turbulence in the umbrella cloud on dispersion and sedimentation of tephra \citep{koyaguchi2009effect}, determination of the entrainment coefficients of eruption columns as a function of height \citep{suzuki2010numerical} and investigation of the effect of wind field on entrainment coefficient \citep{suzuki20133d}. 

While SK-3D focuses on accurately capturing the entrainment caused by turbulent mixture with higher resolution and numerical method of higher order, PDAC takes the disequilibrium between different phases into account and hence is a true multiphase model. Another 3D model, ATHAM (Active Tracer High-Resolution Atmospheric Model) \citep{oberhuber1998volcanic} focuses more on microphysics within the plume. As pyroclastic flow is not the initial concern of ATHAM, dynamic and thermodynamical equilibrium is assumed in ATHAM. The dynamic core of ATHAM solves the compressible Euler equations for momentum, pressure and temperature of the gas particle mixture \citep{oberhuber1998volcanic}. The subgrid-scale turbulence closure scheme differentiates between the horizontal and vertical directions \citep{herzog2003prognostic} captures turbulent mixing. The cloud microphysics predicts the mass of hydrometeors in liquid and ice phase \citep{herzog1998effect}. Additional modules, including gas phase chemistry \citep{trentmann2002simulation} and gas scavenging by hydrometeors \citep{textor2003injection} were added lately. A further extension was made to include particle aggregation \citep{textor2006volcanic1, textor2006volcanic2}. However, the resolution of ATHAM is still coarse compared with SK-3D and PDAC.

Besides adding to their special strengths (ATHAM has been adding more and more microphysics, PDAC was extended to consider more phases), these models are also adding core strengths. PDAC development has begun to include the effect of microphysics into the model while ATHAM development has extended its ability to modeling pyroclastic flow. Both are using finer and finer resolution. 

Recently, a first order, nonequilibrium compressible 3D model, ASHEE \citep{cerminara2016ashee}, was introduced based on three dimensional N-phases Eulerian transportation equations, which are a full set of mass, momentum and energy transport equations for a mixture of gas and dispersed particles. ASHEE is valid for low concentration and low Stokes number region and much faster than N-phases Eulerian model. The model is based on the open source numerical solver OpenFOAM \citep{weller1998tensorial}, adapting its unstructured finite volume solver.

To summarize, each 3D model has its own focus based on the problem of interest and modeling/numerical choices made.
Accuracy of simulation (depending on comprehensiveness of the model, resolution of discretization, numerical error, and order of accuracy) and simulation time (depending on number of governing equations, resolution, numerical methods and parallel techniques) are always conflicting considerations in 3D plume simulations.

\section{Motivation of Developing 3D Model Based on SPH}

All of the existing 3D plume models use mesh based Eulerian methods, and there are no 3D plume models based on mesh free Lagrangian methods. Lagrangian methods have several features that are suitable for volcanic plume simulation that we outline below. Among such Lagrangian methods, smoothed particle hydrodynamics \citep{gingold1977smoothed,lucy1977numerical} based simulations have shown good agreement with experiments for many applications in fluid dynamics. Currently it is, by far, the most widely used mesh-free scheme.
Besides providing source terms for VATDs, I choose SPH as the numerical method for volcanic plume simulation to enable:
\begin{itemize}
\item better investigation of mixing phenomena;
\item accurate modeling of the development of ZFE (Zone of Flow Establishment), ZEF (Zone of Established Flow) investigation and relation to column collapse and the questions relating to the development of entrainment;
\item easy inclusion of particles of different sizes (phases) and investigation of detailed mechanics of sedimentation and drag force interaction in lower plume.
\end{itemize}

These are enabled by the following features of SPH:
\begin{itemize}
\item Advection term in the Navier-Stokes and Euler equations does not appear explicitly in discretized formula of SPH (as illustrated in Eq. (\ref{eq:gov-nc-rho}) to Eq. (\ref{eq:gov-nc-e})).
\item It is easy to include various physics effects (like self gravity, radiative cooling and chemical reaction) into the model. It does not require a major overhaul and re-tooling every time new physics is introduced \citep{monaghan1995sph}. This implies that accounting for more physics is easier for SPH model.
\item With more than one phase, each described by its own set of particles, interface problems between phases are often trivial for SPH but difficult for mesh based schemes. So multiphase flow can be easily handled by SPH. Adding of new phases to the model also does not require a major overhaul and re-tooling. As will be shown in later paragraphs, adding of new phases only leads to adding of several lines into the source code for new phases and additional interaction terms between existing phases and newly added phases.
\item Interface tracking is explicit in SPH through capturing of the locations of the particles. Less numerical effort is required for interface construction when we attempt to include the effects of mixing by resolving the detailed interface structure and dynamics of turbulence.
\end{itemize}

As discussed in the previous paragraph, existing 3D plume models focus on one or several specific aspects of plume and have been extended to be more comprehensive by accounting for more physics or more phases. Easy extensibility and capability of handling multiple phase flow with less additional numerical effort greatly facilitate future extension of SPH models. As volcanic plumes are in nature multiphase and without pre-defined boundary in the atmosphere, SPH is a suitable numerical method for plume modeling. The core physics, such as entrainment of air and thermal expansion, are essential for all plume modeling while some other physics, such as water condensation and aggregation etc., are important in specific scenarios. As an initial effort on exploiting advantages of SPH in volcanic plume modeling, we focus on capturing basic features in plume development using a robust numerically and computationally efficient framework with support for scalable parallel computing. %So our current model is far away from comprehensive. 

The final product of this work is an open source computational software, named Plume-SPH for volcanic plume modeling. Open source availability and the relatively easy extensibility of SPH will facilitate development of a more comprehensive community driven model.

\section{Numerical Challenges}

\subsection{Compressible high speed multiphase turbulent flow}
Portition of numerical challenges are raised by lack of implementations of SPH in compressible multiphase turbulent flow simulation, even though SPH has been known for several decades.

Researches of multiphase flow using SPH focus on constructing the interface between two incompressible fluids which is theoretically a stretched surface of zero thickness and it separates two different fluids at different pressure which is balanced by the surface tension.
\citet{colagrossi2003numerical} adopted several remedies over standard SPH to improves the stability and removes fictitious surface-tension effects present in the standard SPH. The new algorithm was implemented for numerical simulation of air entrapment in violent fluid-structure interactions. \citet{hu2007incompressible} developed numerical techniques to guarantee satisfactory of the zero-density-variation condition and the velocity-divergence-free condition in incompressible multiphase flow. \citet{adami2010new} proposed weakly compressible and incompressible multiphase SPH solvers in their papers focusing on handling of surface-tension force. \citet{monaghan2013simple} also proposed new formulations for weakly compressible fluid with speed of sound sufficiently large to guarantee that the relative density variations are typically $1\%$. Besides variations of standard SPH formulation, he included a repulsion force between different fluids without mathematically rigrious reason. \citet {chen2015sph} recently presented a new SPH model for weakly compressible multiphase flows with complex interfaces and large density differences. Their multiphase SPH model is based on the assumptions of pressure continuity without using any velocity smoothing algorithm or artificial surface tension. To improve the computational accuracy and smooth pressure field, the widely used density re-initialization is applied. In addition, a cut-off value of the particle density is applied to avoid negative particle pressures, which helps to stablize the simulation but might be unphysical. None of them focus on compressible multiphase flow.
In compressible flow, there is no need to worry about zero-density-variation condition. Our assumption of immediate dynamic equilibrium between entrained air and erupted material leads to smooth change of pressure accross interface. Only density of each phases are updated separately and might be different accross interface. Thereby no need to worry about surface tension.
 
These researches presented up to date pay less attention to interface capturing and mixing in multiphase flow. It is critical to capture or track the interface during simulation for immiscible multiphase flow. During the process of volcano plume development, the erupted material and surrounding air are miscible. Mixing between erupted material and atmosphere is more critical for volcanic plume simulation. Even though, clear transient interface do exist in miscible flow. There are experiments \citep {papantoniou1989large} showing clear interface between air and plume. Another experiment with higher resolution shows more detailed and more complicated interface \cite{crimaldi2001high}. 
It is through the interface (or boundary) where mxing happens. \citet{jacobson2008mixing} studied detailed mixing mechanism at a flat interface. Interface construction is fundamental when we attempt to include the effects of mixing by resolving the detailed interface structure and dynamics of turbulence. Quantifying the mixing in this way is challenging because of the scale disparity between the large-scale fluid motion and the diffusion processes on interface that ultimately lead to mixing. Ideally, one would like to be able to include the effects of mixing on the large scale dynamics without resolving the detailed interface structure and dynamics of turbulence to reduce computational cost. Such a strategy was also used in all other mesh-based 3D plume models \citep{oberhuber1998volcanic, neri2003multiparticle, suzuki2005numerical, cerminara2016ashee} (though different turbulence closures were adopted by different models). As will be discussed in following paragraph, turbulence model is also necessary to capture turbulent momentum and energy exchange with coarse resolution.

Another challenge is raised by large Reynolds number in plume development.
The initial velocity of explosive eruption ranges between several tens of meters per second to several hundreds of meters per second generating large Reynolds number. For high speed shearing flow, the momentum exchange and heat transfer are dominated by turbulent fluctuations as turbulent exchange coefficients are several magnitudes larger than corresponding physical coefficients (molecular viscosity and heat conduction coefficient). 
One way to include enough turbulence in the model is to use the SPH-SPS (SPH sub-particle-scale) turbulence model.
Among the first papers on SPH-SPS turbulence models are the implementations of the $SPH-\alpha$ turbulence model \citep{holm1999fluctuation, monaghan2002sph} and the RANS (Reynolds averaged Navier-Stokes) approach \citep{violeau2007numerical}. The first wall-bounded LES (large eddy simulation) simulation with SPH was performed by \citet{issa2005numerical}. An improved version of $SPH-\alpha$ method  \citep{monaghan2002sph} is proposed by \citet{monaghan2011turbulence}, which we refer to as $SPH-\varepsilon$ method. I adopt $SPH-\varepsilon$ method in my model. However, all researches regarding turbulence model constrain their focus to incompressible flow. Thereby I extended the turbulence model to compressible flow simulation.

\subsection{Mixing challenge}

The mixing between erupted material and surrounding air is one of the key factors that determine the development of volcanic plume. 
But classical SPH has problems correctly integrating fluid instabilities and mixing at boundaries \citep{read2010resolving}. We will call it ``mixing challenge" in later paragraph for short.

The ``mixing challenge" is actually has already been discussed in the previous subsection. The author persist believing that the fundamental mechanism of mixing lies on the subtle interface between two phase. A good turbulence model, currently seems to be the best choice for handle this issue considering the substantial amount of computational cost associated with subtle interface construction. However, since there are different opinions and attempts to address this issue, a brief reiview on these opinions is presented in this subsection. Several techniques, which are adopted in current work to address other issues (other than the ``mixing challenge"), turn out to coincide with some strategies proposed to handle ``mixing challenge" by other researchers. These remedies include corrected formulation for tensile instability issue, smaller artificial viscosity coefficients, turbulence model including heat transfer effects.

\citet{read2010resolving} proposed several remedies over classical SPH to handling the ``mixing challenge". One of these remedies is based on fixing the clumping instability which is actually tensile instability. A different method \citep{chen1999improvement} is adopted in present work to handle this clumping issue. \citet{agertz2007fundamental} did a Kelvin-Helmholtz (KH) test showing that using smaller artificial viscosity coefficient can help get more mixing (Fig. 15 and discussion in Section 6.1 in his paper). In our model we also use a much smaller artificial viscosity based on parametric calibration. $\alpha =0.3$ is adopted, while traditionally $\alpha$ is taken as $1$. The original motivation of using smaller artificial viscosity was to avoid excessive artificial viscosity. As will be discussed in the next subsection, two new SPH scheme, the GSPH (Godunov SPH) and RSPH (Random Choice SPH) are also attempted to reduce artificial dissipation. \citet{price2008modelling} believes that the mixing issue is due to the fact that entropy is discontinuous at the boundaries while density is continuous. He found that adding thermal conductivity at boundaries can improve mixing in SPH as thermal conductivity can smooth the entropy. Such strategy has similar effect as the methods proposed by \citet{read2010resolving}. The thermal conductivity (heat transfer) due to turbulence is considered in our model, and the thermal conductivity coefficient is much larger at the interfaces due to large shearing effect there. This can definitely help to relieve the ``mixing challenge" if Price is correct. While, we were not motivated by Price's paper to adding a turbulent heat transfer term into our model -- we were motivatd by the need to have a turbulent heat transfer term for compressible flow in which energy conservation equation is coupled with momentum conservation and mass conservation equation.
\citet{wadsley2008treatment} and \citet{ritchie2001multiphase} made similar arguments as Price. \citet{borgani2012hydrodynamic} believes that the ``mixing challenge" of SPH is due to its poor ability of capturing contact discontinuity. They show that using GSPH can avoid appearance of spurious pressure force and help to to follow the Kelvin instability. GSPH and RSPH, with approximate Riemann solver which accounts for contact discontinuity wave, such as HLLC, are better than classical SPH in terms of capturing contact discontinuity.

Since people still have different opinions on the sources of ``mixing challenge", it would be interesting to see the connections between these different opinions. Remedies of traditional SPH that are adopted and extended unintentionally in present work helping to overcome or at least relieve the ``mixing challenge".

\subsection{Artifcial viscosity}

Volcano plume might be supersonic with maximum eruption speed of hundreds meters per second.
Historically, SPH has difficulty in capturing discontinuities, such as shocks or contact discontinuities. Inviscid description of fluids becomes invalid at shock fronts, where specific entropy of the fluids increases through the conversion of mechanical energy into internal energy. Most SPH codes have included an artificial viscosity term explicitly, both for stabilizing the simulation and for handling shock discontinuities by dissipating local velocity differences and converting them into heat \citep{monaghan1983shock, monaghan1997sph, klapp2012strong}. Without knowing the minimum amount of dissipation for shock capturing, such methodology usually provides dissipation more than need and smears the discontinuity if the artificial viscosity coefficients are not tuned. The method of using constant artificial viscosity might also introduce spurious effects at region away from shocks, for instance, causing an unphysical damping of turbulent mixing (as shown, for example, by \citet{borgani2012hydrodynamic}) or spurious
shearing torques in rotating flows \citep{flebbe1994smoothed}. Selective application of artificial viscosity techniques, such as the time dependent viscosity \citep{morris1997switch, dolag2005turbulent} and shock-indicator-based viscosity \citep{cullen2010inviscid} have been tried for counteracting this. 
\citet{sigalotti2008adaptive} improved the standard SPH near sharp discontinuities adopting adaptive density kernel estimation (ADKE) techniques. However, the parameters for ADKE have to be tuned to the problem at hand \citep{puri2014comparison}. Hence it is hard to implement ADKE in real applications.

Besides adding dissipation explicitly, \citet{inutsuka2002reformulation} proposed an innovative approach to introduce dissipation implicitly by reformulating the SPH convolution integrals. Artificial viscosity is introduced implicitly by using iterative solution to a Riemann problem at an imaginary interface between an interacting particles pair. This method, named as Godunov SPH, is attractive because it eliminates parameterization and hence user intervention associated with artificial viscosity coefficients. The GSPH method has been shown to be able to handle shock discontinuities \citep{inutsuka2002reformulation, cha2003implementations,iwasaki2011smoothed, puri2014approximate}, introduces less damping to turbulent mixing \citep{cha2010kelvin, borgani2012hydrodynamic} than standard SPH, and ameliorate pressure ``blips" (or ``wiggle" called by others) at the contact discontinuity \citep{borgani2012hydrodynamic}. However, the amount of dissipation introduced by GSPH is stll excessive than needs. When using a linear interpolation of the volume function, it has been shown \citep{borgani2012hydrodynamic} that the excess of diffusion, which manifests itself in the shock tube tests as a smooth transition at the rarefaction fan, is such to prevent the development of the KH instability.

Our initial attempt of implementing GSPH in plume model simulation resulted in collapse plume implying necessity of reducing artificial viscosity further. With such motivation, a new SPH scheme, named as RSPH, is proposed by integrating RCM (random choice method) within framework of SPH. 
The new scheme inherits the attraction of classical RCM, introducing less but sufficient artificial viscosity causing less smearing of discontinuities than other methods for 1D problems. What's more, such desirable property of RCM method in 1D is retained in higher dimensional implementations while for classical RCM, which is implemented within framework of mesh based method, such attractive property only retains in 1D implementation. 
RSPH has the following advantages over standard SPH:
\begin{itemize}
\item RSPH is able to capture discontinuities with less smearing.
\item The RSPH is able to adaptively adjust equivalent artificial viscosity coefficients, assigning larger artificial viscosity coefficients around the shock and smaller artificial viscosity coefficients otherwhere.
\item RSPH is able to alleviate pressure ``wiggle" at the contact discontinuity, a common issue in classical SPH.
\end{itemize}
Compared with GSPH, which is also based on solution of local Riemann problems, RSPH introduces less but sufficient dissipation than GSPH, especially in the region away from shocks. Such feature of RSPH is especially beneficial for simulating of scenarios involving turbulence mixing, for which excessive dissipation would suppress mixing. In addition, RSPH also shows faster convergence rate than GSPH. 1D and 3D simulations are carried out to compare classical SPH, GSPH and RSPH regarding amount of artificial viscosity introduced by each method.

\subsection{Boundary conditions}
Three types of boundary conditions are involved in Plume-SPH. The most popular implementations of SPH (and their original motivating implementation) has been in the simulation of free surface flow, such as breaking-waves and floods, which only involve wall boundary condition. Plenty of researches have been carried out regarding imposing of wall boundary conditions in SPH. Traditionally either ghost particles that mirror real particles across the boundary \citep {ferrari2009new} or boundary forces \citep {monaghan2009sph} have been used to impose the wall boundary conditions. One disadvantage of the latter  is that the boundary forces tend to corrupt the solution in the local neighborhood. A variation \citep {kumar2013parallel} of the ghost particle method is adopted in this thesis. Since less attention was paid to velocity inlet and pressure outlet boundary conditions which are required in plume modeling, accurate and computationally efficient way of imposing these two boundary conditions are developed in this thesis.

\section{Parallelization of SPH solver}

Accuracy of simulation and computational time to complete simulation are always conflicting considerations in 3D plume simulations. Accurate prediction of complicated phenomena like volcano plume in a given time window requires resolution (very high particle counts) that can not be accomplished without parallel computing. In addition, many physical effects are ignored or simplified in current version of Plume-SPH. These physical effects might become significant in some scenarios. Easy extensibility of SPH makes including of more physics easy in terms of programming. But more comprehensive physical model will be more computationally expensive. HPC need be leveraged to support more comprehensive plume model.

Parallelism of SPH solver are attempted by many researchers on both Multi-core CPU (central processing unit) and GPGPU (general purpose graphics processing unit). Wenbo \cite{wenbo2014performance} presented a parallel SPH implementation on multi-core CPUs. Holmes \cite{holmes2011framework} presented a simulation framework that enables distributed numerical computing in multi-core shared-memory environments. Dominguez \cite{dominguez2011optimization} presented optimizations for both CPU and GPU parallelization of a SPH method. To bypass the memory constrain of single computational node, MPI technique has been introduced to harness the advantage of distributed memory system, where hundreds of GPUs (or computatinal nodes) can be connected within a network. For exmaple, Goozee \cite{goozee2003distributed} implemented a simple SPH code using MPI, OpenMP and BSP. 
Ferrari \cite{ferrari2009new} parallelized a 3D SPH code using the message passing interface (MPI) standard, together with a dynamic load balancing strategy to improve the computational efficiency of the scheme. Kumar et. al. \cite{kumar2013parallel} implemented a parallel Godunov SPH in simulation of granular flows. Crespo \cite{crespo2015dualsphysics} used the GPUs to accelerate DualSPHysics by up to two orders of magnitude compared to the performance of the serial version. \citet{ji2016large} 
extended a single GPU SPH scheme to multi-GPU platform basing on an improved 3D domain decomposition and inter-node data communication strategy. \citet{oger2016distributed} discussed the various specificities affecting the parallelization of the SPH and particle methods in the context of massively parallel on thousands of cores.
The present work focuses on parallism using MPI technique on a distributed system. Even though the hybrid parallelism, either combining MPI with multi-core parallelism or GPGPU, could take more advantage of computer clusters, it will not attempted in this thesis.

Parallelizing a particle-based code on moderate numbers of cores can easily lead to an acceptable scalability while a scalable speedup on thousands of cores is much more difficult to obtain. The SPH method displays various peculiarities which naturally influence the adopted parallelization strategy, and affect the final speedup and expected efficiency. These aspects include: neighbour particle searching, domain decomposition and losing of load balance due to movement of particles. Besides peculiarities due to SPH method, extra requirements are imposed by the application and long term target. Imposing some types of boundary conditions (such as wind field, eruption boundary condition at the vent) requires dynamically adding and removing particles during simulation. This requires an efficient and flexible data management scheme. Most implementations of the parallel SPH method presented to date are limited to standard SPH and benchmark problems like dam breaks, or relatively simple scenarios like breaking-waves, flooding, etc. While most of the peculiarities due to features of SPH are addressed, less attention is paid to efficient and flexible data management, which is necessary for any implementations of SPH in solving complicated problems. In addition, the flexibility of our data access methodology enables implementing mesh-free methods for solving more complicated problems and using more advanced techniques, such as dynamic particle splitting techniques\cite{vacondio2012accurate, feldman2007dynamic}, which will give higher resolution at the area of interest by splitting one large particle to several smaller ones.

The popular strategy, constrain neighbour searching in a subdomain by background grid, is adopted to reduce neighbour searching cost. Different domain decomposition strategies were attempted to handle workload imbalance raised by movement of SPH particles. \citet{dominguez2013new} applied a dynamic load balancing scheme improved the scalability and efficiency of multi-GPU SPH. The number of particles is adjusted basing on the runtime in each subdomain to achieve good load balance. One drawback of these strategies is that the domain decomposition is only in one dimension. Such strategies are extended to 2D domain decomposition by \citet{rustico2014advances}. \citet{oger2016distributed} presented and evaluated domain decomposition based on the notion of Orthogonal Recursive Bisection (ORB). This thesis adopt an easy-programming scheme based on SFC \cite{patra1999efficient} to decompose the domain.

Among existing CPU parallel SPH schemes, most of them focus on neighbor searching algorithms and dynamic load balancing. (eg. \cite{ferrari2009new, crespo2015dualsphysics}). Less attention has been paid to developing more flexible data management schemes.
Fortunately, efficient and flexible data management strategies for parallel computing have been successfully implemented in mesh based methods (eg. \cite{laszloffy2000simple} for adaptive hp finite element method (FEM), and \cite{patra2005parallel} for finite volume method (FVM)). Motivated by these techniques developed for mesh based methods, we present a complete framework for parallelizing SPH program with the MPI standard allowing flexible and efficient data access.

As for the actual storage of data representing the physical quantities associated to each particle, different strategies have been adopted in existing implementations of SPH. 
In DualSPHysics\cite{crespo2015dualsphysics}, the physical quantities of each particle (position, velocity, density...) are stored in arrays, and the particles (and the arrays with particle data) are reordered following the order of the cells. It is not flexible enough to add, delete and especially access particles for such fixed-size arrays. Ferrari\cite{ferrari2009new} adopted linked lists using pointers so that particles can be deleted or added during the simulation. Storage problems caused by fixed-size arrays are thereby also eliminated. However, the element access speed becomes slow when totla number of particles are large. Neither array nor list is able to achieve both flexibility and efficiency in terms of data management. In this thesis, hash table is attempted to achieve both flexibility and efficiency.

Some specific feature of the application can be utilized to improve computational efficiency. To the best of the author's knowledge, no current implementation of SPH has the feature of adjusting the computational domain based on simulation needs. For volcano plume simulation, this feature will greatly reduce computational cost by avoiding computing of uninfluenced fluids.

\section{Summary}
This thesis targets at provinding the first Lagrangian method based 3D volcanic plume simulation software (Plume-SPH) which can be used to generate more accurate initial condition for volcanic ash transportation forecasting. A two phase dusty-gas plume model is adopted representing eruption of well-mixed fine ash size erupted material from a flat ground into stationary atmosphere. SPH method is implemented, extended and taiored to address all relevant numerical challengings. The architecture of the software is designed to support efficient and flexible parallel computing. The output of the software is successfully used as input by a VATD eliminating user intervention improving forecast capability of volcanic ash transportation and dispersion. The following are major contribution of this thesis.

\begin{itemize}
\item Methodology to impose pressure boundary conditions is developed by adding extra layers of static ghost particles. Additional constraints on the time step are used to avoid the growth of numerical fluctuations near the pressure boundary. Velocity inlet boundary condition is imposed by placing several layers of ghost particles moving with eruption velocity.
\item Several remedies regarding standard SPH is adopted to address numerical challenges in the specific application, such as, the corrected formulation of SPH \citep{chen1999improvement}.
\item  A LANS (Lagrangian Averaged Navier-Stokes) turbulence model \citep{monaghan2011turbulence}, which was originally proposed for incompressible flow, is adopted and extended for compressible flow accounting for turbulent heat exchange based on Reynolds analogy.
\item A new SPH scheme is proposed by integrating Random Choice Method (RCM) into SPH framework obtaining a new numerical scheme which introduces less but sufficient artificial viscosity compared with standard SPH and GSPH.
\item The core solver of Plume-SPH is parallelized by distributed memory MPI (message passing interface standard) parallelism. In addition, a dynamic load balancing strategy is also developed. 
\item An efficient data management scheme is developed based on time dependent SFC (space filling curve) induced indexing and hash table with external linked list. The computational cost is further reduced by adjusting simulation domain adaptively.
\item I carry out, for the first time, numerical volcanic ash transportation and dispersion simulation based on initial condition generated by 3D plume simulation and obtain good match with observation without any parameters calibration.
\end{itemize}

The physical model of the volcano plume, together with the analysis on hyperbolicity of the governing equations, are introduced in Chapter \ref{chapter:physics-model} of the thesis. Chapter \ref{chapter:classical-SPH} is dedicated to presenting
classical SPH method and discretization of the giverning equation using classical SPH. Two new SPH schemes, the GSPH and RSPH, are presented in Chapter \ref{chapter:GSPH-RSPH} aiming at introducing artificial minimum but sufficient artifical viscosity. Chapter \ref{chapter:architecture-parallelism} is dedicated to code architecture and parallelization of the software. In Chapter \ref{chapter:case-studies} the software is first verified by some bench mark problems, then the numerical simulation of the dynamics of volcanic eruption processes
performed by this software are reported and discussed. The software is spplied to create initial conditions for volcanic ash transportation forecasting in Chapter \ref{chapter:ash-transportation}. Finally, in Chapter \ref{chapter:Future-Work}, I
write some concluding remarks and outline some directions for future work.